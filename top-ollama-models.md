# Top 10 Ollama Models with Tool Calling Support for M2 Mac (24GB RAM)
## Based on Official Ollama Registry (Sorted by Popularity + Tool Support)

1. **llama3.1:8b** ✅ (Downloaded)
   - 98.5M pulls, 93 tags
   - Size: ~4.9GB
   - Meta's flagship model with excellent tool support
   - Perfect balance of performance and resource usage

2. **qwen2.5:7b** ✅ (Downloading)
   - 11.5M pulls, 133 tags
   - Size: ~4.7GB
   - Alibaba's latest with 128K context, multilingual
   - Strong tool calling and reasoning

3. **llama3.2:3b** ✅ (Downloaded)
   - 26.4M pulls, 63 tags
   - Size: ~2.0GB
   - Fast inference, compact size
   - Great for quick tool-enabled responses

4. **mistral:7b**
   - 16.9M pulls, 84 tags
   - Size: ~4.1GB
   - Updated to v0.3, reliable tool calling
   - Good general-purpose performance

5. **qwen2.5-coder:7b**
   - 5.8M pulls, 199 tags
   - Size: ~4.4GB
   - Code-specialized with excellent tool support
   - Perfect for development workflows

6. **qwen3:8b**
   - 4M pulls, 35 tags
   - Size: ~4.7GB
   - Latest Qwen generation with thinking capability
   - Advanced reasoning + tool calling

7. **deepseek-r1:8b** ❌ (No tool support)
   - 54.4M pulls but lacks tool calling in Ollama
   - Skip despite popularity

8. **phi4-mini:3.8b**
   - 231.9K pulls, 5 tags
   - Size: ~2.3GB
   - Microsoft's compact model with new function calling
   - Enhanced math and multilingual support

9. **granite3.3:8b**
   - 228.3K pulls, 3 tags
   - Size: ~4.7GB
   - IBM's latest with 128K context
   - Designed for reasoning and instruction-following

10. **hermes3:8b**
    - 305.9K pulls, 65 tags
    - Size: ~4.7GB
    - Nous Research flagship with tool support
    - Great for conversational AI agents

## Notes:
- All models fit comfortably in 24GB RAM
- Models 1-6 are the best balance for your setup
- Prioritize models 1-3 for daily use
- Model #10 is for when you need maximum capability
- All support the OpenAI-compatible tools API